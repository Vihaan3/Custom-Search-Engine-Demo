{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYqsrxOZ9omEn7IgG4BoXy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vihaan3/Custom-Search-Engine-Demo/blob/main/Karpathy_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3T22s0u7c-2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Makemore Part 1"
      ],
      "metadata": {
        "id": "vaV7JpebFNni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('/content/names.txt', 'r').read().splitlines()\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "g = torch.Generator().manual_seed(2147483647)"
      ],
      "metadata": {
        "id": "cYQ-ghbh-lkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A pared down version of the neural network in the original video."
      ],
      "metadata": {
        "id": "5O8dCeUjEvTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num)\n",
        "\n",
        "# initialize the 'network'\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHJ69VG2-3-5",
        "outputId": "7eefae46-a6a0-48d6-f891-077dbab106a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of examples:  228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(100):\n",
        "\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "  logits = xenc @ W # predict log-counts\n",
        "  counts = logits.exp() # counts, equivalent to N\n",
        "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "\n",
        "  if k % 10 == 0:\n",
        "    print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W.data += -50 * W.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd8AoNQq_DmV",
        "outputId": "769191c8-7937-4add-9d92-124c35f30f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7686190605163574\n",
            "2.696505546569824\n",
            "2.5822560787200928\n",
            "2.5413522720336914\n",
            "2.52126407623291\n",
            "2.509854555130005\n",
            "2.5027060508728027\n",
            "2.4978790283203125\n",
            "2.4944381713867188\n",
            "2.4918932914733887\n",
            "2.4901304244995117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "\n",
        "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
        "    logits = xenc @ W # predict log-counts\n",
        "    counts = logits.exp() # counts, equivalent to N\n",
        "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzEzeefFBMzK",
        "outputId": "2572909a-1d8f-4636-ad91-9a12d6c0a3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "junide.\n",
            "janasah.\n",
            "p.\n",
            "cfay.\n",
            "a.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss: 2.49\n",
        "\n",
        "Text Generated:\n",
        "- junide.\n",
        "- janasah.\n",
        "- p.\n",
        "- cfay.\n",
        "- a."
      ],
      "metadata": {
        "id": "jCIVSnC1XhBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### E01: Trigram\n",
        "I wasn't sure at first whether increasing the right way to go was increasing the size of the input dimension or adding another dimension so I decided to try both. Also, note that my code here is meant to resemble Andrej Karpathy's, which is intentonally a little bit hacky for educational purposes. This is not what a \"production\" implementation would look like."
      ],
      "metadata": {
        "id": "QtFUxfxYFvu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### V1: Additional Dimension"
      ],
      "metadata": {
        "id": "CUgtOrSzXOhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import einops"
      ],
      "metadata": {
        "id": "zTxpJB96HY4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.', '.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    xs.append((ix1, ix2))\n",
        "    ys.append(ix3)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement() // 2 # dividing by 2 now because the shape of xs has changed\n",
        "print('number of examples: ', num)\n",
        "\n",
        "W1 = torch.randn((27, 27, 27), generator=g, requires_grad=True) # 3D now"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGFiTcvTDSK3",
        "outputId": "44ec45b5-c519-4822-fcfb-98f8292a1f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of examples:  228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(100):\n",
        "\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(xs[:, 0], num_classes=27).float() # character 1\n",
        "  xenc2 = F.one_hot(xs[:, 1], num_classes=27).float() # character 2\n",
        "  logits = einops.einsum(xenc, W1, xenc2, \"b i, i j k, b j -> b k\") # you might have to ask GPT about this line. Understand what's happening but don't stress it, it'll make more sense soon.\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W1**2).mean()\n",
        "\n",
        "  if k % 10 == 0:\n",
        "    print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  W1.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W1.data += -50 * W1.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_lZNzfIF9Pc",
        "outputId": "7a2918f1-5bcd-4098-c68c-29964eb1e97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6517415046691895\n",
            "2.8801517486572266\n",
            "2.6203973293304443\n",
            "2.471735715866089\n",
            "2.373619794845581\n",
            "2.3028182983398438\n",
            "2.2486462593078613\n",
            "2.205559015274048\n",
            "2.1703648567199707\n",
            "2.1410269737243652\n",
            "2.1184768676757812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "\n",
        "  out = []\n",
        "  # couldn't decide on good var names so I thought I would be funny\n",
        "  uno = 0\n",
        "  dos = 0\n",
        "  while True:\n",
        "\n",
        "    xenc = F.one_hot(torch.tensor(uno), num_classes=27).float().unsqueeze(0)\n",
        "    xenc2 = F.one_hot(torch.tensor(dos), num_classes=27).float().unsqueeze(0)\n",
        "    logits = einops.einsum(xenc, W1, xenc2, \"b i, i j k, b j -> b k\")\n",
        "    counts = logits.exp()\n",
        "    p = counts / counts.sum(1, keepdims=True)\n",
        "\n",
        "    uno = dos\n",
        "    dos = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[dos])\n",
        "    if dos == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A6imbZyChjH",
        "outputId": "0a91b829-6f47-4866-c3a5-320bbf2ec7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ni.\n",
            "makestobfzwruvbvjxpxdznleanczqwmdemyw.\n",
            "mkzdnseira.\n",
            "na.\n",
            "umjoebvsdfyhoujfodpmvuhdgdohupy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss: 2.12\n",
        "\n",
        "Text Generated\n",
        "- coud\n",
        "- qipny\n",
        "- hafijcpydhrdqzieqiupfdcaanvinegnhiyah\n",
        "- dae\n",
        "- hatea\n",
        "\n",
        "Lower loss but also lower quality outputs than the original. Seems like overfitting.\n",
        "\n",
        "Curiously, when I train for 1000 steps instead, I get these results:\n",
        "\n",
        "Loss: 1.49\n",
        "\n",
        "Text Generated\n",
        "- ouwade\n",
        "- ilyasid\n",
        "- prelay\n",
        "- ocnzi\n",
        "- ohr\n",
        "\n",
        "These seem much higher quality than the original.  "
      ],
      "metadata": {
        "id": "MYv7E7g7X2ih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### V2: Bigger input dimension"
      ],
      "metadata": {
        "id": "78MMEDwyYDZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.', '.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    xs.append((ix1, ix2))\n",
        "    ys.append(ix3)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement() // 2 # dividing by 2 now because the shape of xs has changed\n",
        "print('number of examples: ', num)\n",
        "\n",
        "W2 = torch.randn((27*2, 27), generator=g, requires_grad=True) # still 2D but now the input dimension is double"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYKl5J4FQkPf",
        "outputId": "d2d2ddd7-89ba-4e4c-86e1-707b44341b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of examples:  228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(100):\n",
        "\n",
        "  # forward pass\n",
        "  '''Edit: a cleaner implementation would be:\n",
        "  xenc = F.one_hot(xs, num_classes=27).float()\n",
        "  logits = xenc.view(-1, 27*2) @ W2\n",
        "  '''\n",
        "  xenc = F.one_hot(xs[:, 0], num_classes=27).float() # character 1\n",
        "  xenc2 = F.one_hot(xs[:, 1], num_classes=27).float() # character 2\n",
        "  xcat = torch.cat ((xenc, xenc2), 1)\n",
        "  logits = xcat @ W2\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W2**2).mean()\n",
        "\n",
        "  if k % 10 == 0:\n",
        "    print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  W2.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W2.data += -50 * W2.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeXOFDNFREcc",
        "outputId": "0e2ab2d6-0fbf-438e-c01b-1ac3c42536b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.5374555587768555\n",
            "2.16996693611145\n",
            "2.063832998275757\n",
            "2.020979404449463\n",
            "1.9984627962112427\n",
            "1.9848086833953857\n",
            "1.9757133722305298\n",
            "1.9692426919937134\n",
            "1.9644166231155396\n",
            "1.960689663887024\n",
            "1.958001732826233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "\n",
        "  out = []\n",
        "  # couldn't decide on good var names so I thought I would be funny\n",
        "  uno = 0\n",
        "  dos = 0\n",
        "  while True:\n",
        "\n",
        "    xenc = F.one_hot(torch.tensor(uno), num_classes=27).float().unsqueeze(0)\n",
        "    xenc2 = F.one_hot(torch.tensor(dos), num_classes=27).float().unsqueeze(0)\n",
        "    xcat = torch.cat((xenc, xenc2), 1)\n",
        "    logits = xcat @ W2\n",
        "    counts = logits.exp()\n",
        "    p = counts / counts.sum(1, keepdims=True)\n",
        "\n",
        "    uno = dos\n",
        "    dos = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[dos])\n",
        "    if dos == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IslDp05-b7hK",
        "outputId": "aecc8c0f-db42-401a-c2dd-7387fdde6f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            ".\n",
            "mefilayniylenn.\n",
            ".\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss: 1.95\n",
        "\n",
        "Text Generated:\n",
        "- blank\n",
        "- dena\n",
        "- blank\n",
        "- blank\n",
        "- blank\n",
        "\n",
        "Much lower loss but also lower quality generations."
      ],
      "metadata": {
        "id": "okXuaqsNYBSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mKnyq9YBlC8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### E02: Splitting\n",
        "Basic implementation of the splitting. Play around by yourself to answer Andrej Karpathy's question."
      ],
      "metadata": {
        "id": "RimEFXMtlIAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(words)\n",
        "\n",
        "num_words = len(words)\n",
        "train_split = int(0.8*num_words)\n",
        "dev_split = int(0.9*num_words)\n",
        "\n",
        "train_words = words[:train_split]\n",
        "dev_words = words[train_split:dev_split]\n",
        "test_words = words[dev_split:]\n",
        "\n",
        "print(f\"Train Size: {len(train_words)}\")\n",
        "print(f\"Dev Size: {len(dev_words)}\")\n",
        "print(f\"Test Size: {len(test_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZbFeEeqlcY9",
        "outputId": "10196e81-b621-4023-cf0f-dfe9cb272ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Size: 25626\n",
            "Dev Size: 3203\n",
            "Test Size: 3204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### E05: F.cross_entropy\n"
      ],
      "metadata": {
        "id": "mYnWd1dKoVr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From the original. You can turn snippet 1 into snippet 2 using F.cross_entropy\n",
        "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "logits = xenc @ W # predict log-counts\n",
        "counts = logits.exp() # counts, equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "\n",
        "# F.cross_entropy\n",
        "xenc = F.one_hot(xs, num_classes=27).float()\n",
        "logits = xenc @ W\n",
        "loss = F.cross_entropy(logits, ys) + 0.01*(W**2).mean()\n",
        "\n",
        "# Why you want to use F.cross_entropy instead: https://youtu.be/TCH_1BHY58I?t=1979"
      ],
      "metadata": {
        "id": "gJzaErXQo44z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Makemore Part 2: MLP"
      ],
      "metadata": {
        "id": "-hV5_mYJrtPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### E03"
      ],
      "metadata": {
        "id": "m35M4cMlr5-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Makemore Part 3: Activations and Gradients, Batchnorm\n",
        "\n",
        "Not bothering too much with splits here for convenience."
      ],
      "metadata": {
        "id": "2rGv1wZBr-eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup"
      ],
      "metadata": {
        "id": "NaebhmbD_RRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "\n",
        "  def __init__(self, fan_in, fan_out, bias=True):\n",
        "    self.weight = torch.randn((fan_in, fan_out), generator=g) / fan_in**0.5\n",
        "    self.bias = torch.zeros(fan_out) if bias else None\n",
        "\n",
        "  def __call__(self, x):\n",
        "    self.out = x @ self.weight\n",
        "    if self.bias is not None:\n",
        "      self.out += self.bias\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "\n",
        "class BatchNorm1d:\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.momentum = momentum\n",
        "    self.training = True\n",
        "    # parameters (trained with backprop)\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "    # buffers (trained with a running 'momentum update')\n",
        "    self.running_mean = torch.zeros(dim)\n",
        "    self.running_var = torch.ones(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    if self.training:\n",
        "      xmean = x.mean(0, keepdim=True) # batch mean\n",
        "      xvar = x.var(0, keepdim=True) # batch variance\n",
        "    else:\n",
        "      xmean = self.running_mean\n",
        "      xvar = self.running_var\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    # update the buffers\n",
        "    if self.training:\n",
        "      with torch.no_grad():\n",
        "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "class Tanh:\n",
        "  def __call__(self, x):\n",
        "    self.out = torch.tanh(x)\n",
        "    return self.out\n",
        "  def parameters(self):\n",
        "    return []"
      ],
      "metadata": {
        "id": "DkBdPisZ_PdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = [], []\n",
        "block_size = 3\n",
        "n_embd = 10\n",
        "n_hidden = 100\n",
        "block_size = 3\n",
        "vocab_size = len(itos)\n",
        "\n",
        "for w in words:\n",
        "  context = [0] * block_size\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    context = context[1:] + [ix]\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)\n",
        "print(X.shape, Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk0nFxYqCJaV",
        "outputId": "246147cc-705b-4138-afac-7980402ed579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([228146, 3]) torch.Size([228146])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### E01"
      ],
      "metadata": {
        "id": "ysVWRa9K-aUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Setup\n",
        "layers = [\n",
        "  Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  Linear(           n_hidden, vocab_size, bias=False), BatchNorm1d(vocab_size),\n",
        "]\n",
        "C = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True\n",
        "  p.data = torch.zeros_like(p.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S7gXYmoeVkU",
        "outputId": "3363d297-1e43-4a07-ae83-fd9dffa7f2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Training\n",
        "batch_size = 32\n",
        "ud = []\n",
        "for i in range(1000):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, X.shape[0], (batch_size,), generator=g)\n",
        "  Xb, Yb = X[ix], Y[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xb] # embed the characters into vectors\n",
        "  x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "  for layer in layers:\n",
        "    x = layer(x)\n",
        "  loss = F.cross_entropy(x, Yb) # loss function\n",
        "  if i % 100 == 0:\n",
        "    print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  for layer in layers:\n",
        "    layer.out.retain_grad()\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  with torch.no_grad():\n",
        "    ud.append([((lr*p.grad).std() / p.data.std()).log10().item() for p in parameters])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B5oh0fJfgQ9",
        "outputId": "344d7b6f-bd51-4317-a092-83f24666d6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.295837163925171\n",
            "3.044875144958496\n",
            "2.9702932834625244\n",
            "2.840195894241333\n",
            "3.0619606971740723\n",
            "2.819377899169922\n",
            "3.093287467956543\n",
            "2.6854422092437744\n",
            "2.6405556201934814\n",
            "2.8148913383483887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "PlX04BvDijF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect Activations\n",
        "# visualize histograms\n",
        "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
        "legends = []\n",
        "for i, layer in enumerate(layers[:-1]): # note: exclude the output layer\n",
        "  if isinstance(layer, Tanh):\n",
        "    t = layer.out\n",
        "    print('layer %d (%10s): mean %+.2f, std %.2f, saturated: %.2f%%' % (i, layer.__class__.__name__, t.mean(), t.std(), (t.abs() > 0.97).float().mean()*100))\n",
        "    hy, hx = torch.histogram(t, density=True)\n",
        "    plt.plot(hx[:-1].detach(), hy.detach())\n",
        "    legends.append(f'layer {i} ({layer.__class__.__name__}')\n",
        "plt.legend(legends);\n",
        "plt.title('activation distribution')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "iZn5nRESiRkj",
        "outputId": "93d2f0e4-a7fc-4d28-9351-5171c56a211a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer 2 (      Tanh): mean +0.00, std 0.00, saturated: 0.00%\n",
            "layer 5 (      Tanh): mean +0.00, std 0.00, saturated: 0.00%\n",
            "layer 8 (      Tanh): mean +0.00, std 0.00, saturated: 0.00%\n",
            "layer 11 (      Tanh): mean +0.00, std 0.00, saturated: 0.00%\n",
            "layer 14 (      Tanh): mean +0.00, std 0.00, saturated: 0.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'activation distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 262
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize histograms\n",
        "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
        "legends = []\n",
        "for i, layer in enumerate(layers[:-1]): # note: exclude the output layer\n",
        "  if isinstance(layer, Tanh):\n",
        "    t = layer.out.grad\n",
        "    print('layer %d (%10s): mean %+f, std %e' % (i, layer.__class__.__name__, t.mean(), t.std()))\n",
        "    hy, hx = torch.histogram(t, density=True)\n",
        "    plt.plot(hx[:-1].detach(), hy.detach())\n",
        "    legends.append(f'layer {i} ({layer.__class__.__name__}')\n",
        "plt.legend(legends);\n",
        "plt.title('gradient distribution')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "mMs9Fs-3isgO",
        "outputId": "9c01ffad-745c-40dd-eae2-40c6c3afe8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer 2 (      Tanh): mean +0.000000, std 0.000000e+00\n",
            "layer 5 (      Tanh): mean +0.000000, std 0.000000e+00\n",
            "layer 8 (      Tanh): mean +0.000000, std 0.000000e+00\n",
            "layer 11 (      Tanh): mean +0.000000, std 0.000000e+00\n",
            "layer 14 (      Tanh): mean +0.000000, std 0.000000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'gradient distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 263
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9rJU_SzoJXd",
        "outputId": "398fc37a-b5b2-4a2b-f3bf-218dad2f3e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True),\n",
              " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.], requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.], requires_grad=True),\n",
              " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.], requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.], requires_grad=True),\n",
              " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.], requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.], requires_grad=True),\n",
              " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.], requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.], requires_grad=True),\n",
              " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.], requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.], requires_grad=True),\n",
              " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0.], requires_grad=True),\n",
              " tensor([ 1.7434,  1.7875, -0.6373, -0.4330, -0.1051,  1.1860, -1.0945, -0.8538,\n",
              "          0.2938,  1.1738, -0.5858, -0.2047,  0.9024,  0.0959,  1.1567,  0.3386,\n",
              "         -1.0140, -1.2611,  0.8037,  0.3597, -0.0467, -0.5447, -0.6514, -1.0996,\n",
              "         -1.1574,  0.5452, -0.6974], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only updates are in the last layer due to the loss calculation. This is where the \"partial\" training is happening. What I don't get is why none of this \"trickles\" up."
      ],
      "metadata": {
        "id": "Jy2hYKIQn9GP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### E02\n",
        "\n",
        "Folding did not work :( I'm definitely making some stupid error here."
      ],
      "metadata": {
        "id": "JaHCxhFVsMhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Setup\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "C = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "network = [\n",
        "  Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden)\n",
        "]\n",
        "\n",
        "parameters = [C] + [p for layer in network for p in layer.parameters()]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1VC_Ywe-crf",
        "outputId": "a14cf656-f501-4660-f985-b30a80fecd3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Training\n",
        "batch_size = 32\n",
        "for i in range(1000):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, X.shape[0], (batch_size,), generator=g)\n",
        "  Xb, Yb = X[ix], Y[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xb] # embed the characters into vectors\n",
        "  x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "  for layer in network:\n",
        "    x = layer(x)\n",
        "  loss = F.cross_entropy(x, Yb) # loss function\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad"
      ],
      "metadata": {
        "id": "TQ6dWwirBXiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Eval 1\n",
        "@torch.no_grad()\n",
        "def split_loss():\n",
        "  x, y = X, Y\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  x = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  for layer in network:\n",
        "    x = layer(x)\n",
        "  loss = F.cross_entropy(x, y)\n",
        "  print(loss.item())\n",
        "\n",
        "# put layers into eval mode\n",
        "for layer in network:\n",
        "  layer.training = False\n",
        "split_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dohQ4OEZcoaG",
        "outputId": "3b3a95bc-2c9f-48a4-f26c-46ca886606aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5595736503601074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fold function\n",
        "def fold_batchnorm_into_linear(linear, batchnorm):\n",
        "    batchnorm.training = False\n",
        "\n",
        "    # Get parameters\n",
        "    gamma = batchnorm.gamma\n",
        "    beta = batchnorm.beta\n",
        "    running_mean = batchnorm.running_mean\n",
        "    running_var = batchnorm.running_var\n",
        "    eps = batchnorm.eps\n",
        "    W = linear.weight\n",
        "    b = linear.bias if linear.bias is not None else torch.zeros_like(beta)\n",
        "\n",
        "    # Calculate folded parameters\n",
        "    scale = gamma / torch.sqrt(running_var + eps)\n",
        "    W_folded = W * scale\n",
        "    b_folded = (b - running_mean) * scale + beta\n",
        "\n",
        "    # Create new linear layer\n",
        "    folded_linear = Linear(W.shape[0], W.shape[1], bias=True)\n",
        "\n",
        "    # Assign folded parameters\n",
        "    folded_linear.weight = W_folded\n",
        "    folded_linear.bias = b_folded\n",
        "\n",
        "    return folded_linear"
      ],
      "metadata": {
        "id": "YJZ4mEmLDzRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#folding\n",
        "import torch.nn as nn\n",
        "\n",
        "network[0] = fold_batchnorm_into_linear(network[0], network[1])\n",
        "network[3] = fold_batchnorm_into_linear(network[3], network[4])\n",
        "network[6] = fold_batchnorm_into_linear(network[6], network[7])\n",
        "network[2] = nn.Identity()\n",
        "network[5] = nn.Identity()\n",
        "\n",
        "parameters = [C] + [p for layer in network for p in layer.parameters()]\n",
        "print(sum(p.nelement() for p in parameters))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdKTFGe7GkA-",
        "outputId": "f12b9bf4-4bba-415e-d8fb-22a60b4e7234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Eval 2\n",
        "@torch.no_grad()\n",
        "def split_loss():\n",
        "  x, y = X, Y\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  x = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  for layer in network:\n",
        "    x = layer(x)\n",
        "  loss = F.cross_entropy(x, y)\n",
        "  print(loss.item())\n",
        "\n",
        "for layer in network:\n",
        "  layer.training = False\n",
        "split_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy-fUWEXdIup",
        "outputId": "7f07e4a6-aa7e-4621-dda8-4f49f6ad5dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.05037784576416\n",
            "5.05037784576416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I get different losses :(."
      ],
      "metadata": {
        "id": "AUF5kV0Fdhf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPT"
      ],
      "metadata": {
        "id": "E5LWZ72fwLXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### EX2\n",
        "Took surprisingly longer than I thought (3-4 hours of messing around with different ideas until I actually got something that felt reasonable, and then another 2-3 hours of debugging as I realized that it wasn't reasonable at all). Something still feels off, even though the model does learn. I would expect the model to have been able to overfit 1-digit addition quickly, but even after 60K iterations it still only had close-ish answers and loss couldn't quite get past 0.25.\n",
        "\n",
        "I did my best to follow the structure of the code AK used in the video, but I have a cleaner version in gptaddition.py."
      ],
      "metadata": {
        "id": "zn_V3GW9wTEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "\n",
        "# hyperparameters -> convert to dataclass eventually\n",
        "batch_size = 128\n",
        "num_digits = 1\n",
        "block_size = 3*num_digits + 3\n",
        "max_iters = 50000\n",
        "eval_interval = 500\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 20\n",
        "n_embd = 128\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.1\n",
        "vocab_size = 0\n",
        "\n",
        "\n",
        "vocab = '0123456789+='\n",
        "vocab_size = len(vocab) + 1\n",
        "stoi = { ch:i for i,ch in enumerate(vocab) }\n",
        "itos = { i:ch for i,ch in enumerate(vocab) }\n",
        "PAD_TOKEN = vocab_size - 1\n",
        "stoi['P'] = PAD_TOKEN\n",
        "itos[PAD_TOKEN] = 'P'\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])"
      ],
      "metadata": {
        "id": "6tYSE9bZdB5W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem Generation Function\n",
        "def generate_addition_problem(digits=num_digits):\n",
        "  num_1 = random.randint(0, 10**digits -1)\n",
        "  num_2 = random.randint(0, 10**digits -1)\n",
        "\n",
        "  problem = f\"{num_1}+{num_2}=\"\n",
        "  answer = str(num_1+num_2)\n",
        "  if len(answer) < digits + 1:\n",
        "    answer = '0'+answer\n",
        "  return problem, answer[::-1]"
      ],
      "metadata": {
        "id": "_wnM908FdFWO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem Encoding Function\n",
        "def encode_problem(problem, answer, digits=num_digits):\n",
        "  y = [-1] * len(problem)\n",
        "  x = torch.tensor(encode(problem))\n",
        "  y.extend(encode(answer))\n",
        "  y = torch.tensor(y)\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "LGVikeJSdI8E"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem, answer = generate_addition_problem()\n",
        "problem, answer, encode_problem(problem, answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d34moD1KdR7x",
        "outputId": "cc5c6d06-8f3c-48b1-f91a-8afac796dae9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2+4=', '60', (tensor([ 2, 10,  4, 11]), tensor([-1, -1, -1, -1,  6,  0])))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get_Batch Function\n",
        "def get_batch():\n",
        "  xs, ys = [], []\n",
        "  for i in range(batch_size):\n",
        "    x, y = encode_problem(*generate_addition_problem())\n",
        "    x = F.pad(x, (0, block_size - len(x)), value=PAD_TOKEN)\n",
        "    y = F.pad(y, (0, block_size - len(y)), value=-1)\n",
        "    assert len(x) == len(y) or len(y) == block_size\n",
        "    xs.append(x)\n",
        "    ys.append(y)\n",
        "  x_stack = torch.stack(xs)\n",
        "  y_stack = torch.stack(ys)\n",
        "  return x_stack.to(device), y_stack.to(device)"
      ],
      "metadata": {
        "id": "8G7VbnbwOoJs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds, targets = get_batch()"
      ],
      "metadata": {
        "id": "cf4jmJuDkrt_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds[:5], targets[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJFP5yg_kvQI",
        "outputId": "00d16eeb-f56d-4ddd-9f8e-eca0358dfb27"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1, 10,  8, 11, 12, 12],\n",
              "         [ 1, 10,  7, 11, 12, 12],\n",
              "         [ 9, 10,  7, 11, 12, 12],\n",
              "         [ 5, 10,  7, 11, 12, 12],\n",
              "         [ 8, 10,  8, 11, 12, 12]], device='cuda:0'),\n",
              " tensor([[-1, -1, -1, -1,  9,  0],\n",
              "         [-1, -1, -1, -1,  8,  0],\n",
              "         [-1, -1, -1, -1,  6,  1],\n",
              "         [-1, -1, -1, -1,  2,  1],\n",
              "         [-1, -1, -1, -1,  6,  1]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual Model\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input of size (batch, time-step, channels)\n",
        "        # output of size (batch, time-step, head size)\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss_fn = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "            loss = loss_fn(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(block_size):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ],
      "metadata": {
        "id": "KbjHXxM9fzc6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Function\n",
        "def test_generations(model, num_evals = 10):\n",
        "  for i in range(num_evals):\n",
        "    problem, answer = generate_addition_problem()\n",
        "    problem_tensified, _ = encode_problem(problem, answer)\n",
        "    out = model.generate(problem_tensified.unsqueeze(0).to(device))\n",
        "    out = decode([int(x) for x in out[0].tolist()])[len(problem):]\n",
        "    print(f\"Problem: {problem} | Output: {out[:num_digits+1][::-1]}\")"
      ],
      "metadata": {
        "id": "1Ldr1NIiR68-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "3KxxDgbLjvp0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Loop -> trained for a total of 110k iterations\n",
        "for iteration in range(max_iters):\n",
        "  if iteration % eval_interval == 0:\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "      for _ in range(eval_iters):\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch()\n",
        "            logits, loss = model(X, Y)\n",
        "            losses.append(loss.item())\n",
        "    model.train()\n",
        "    mean_loss = torch.mean(torch.tensor(losses))\n",
        "    print(f\"step {iteration}: loss {mean_loss:.4f}\")\n",
        "    xb, yb = get_batch()\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANY_99MN3wAd",
        "outputId": "75b0d5ae-122d-43f1-c83a-6af2364577b4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: loss 0.2159\n",
            "step 500: loss 0.2092\n",
            "step 1000: loss 0.2287\n",
            "step 1500: loss 0.2375\n",
            "step 2000: loss 0.2121\n",
            "step 2500: loss 0.2127\n",
            "step 3000: loss 0.2018\n",
            "step 3500: loss 0.2700\n",
            "step 4000: loss 0.2651\n",
            "step 4500: loss 0.1925\n",
            "step 5000: loss 0.1996\n",
            "step 5500: loss 0.2307\n",
            "step 6000: loss 0.2729\n",
            "step 6500: loss 0.2664\n",
            "step 7000: loss 0.2211\n",
            "step 7500: loss 0.2293\n",
            "step 8000: loss 0.1942\n",
            "step 8500: loss 0.1956\n",
            "step 9000: loss 0.2272\n",
            "step 9500: loss 0.2184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generations(model)"
      ],
      "metadata": {
        "id": "oaZe2TgqPqTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47a72e2-37a9-490e-b73e-4bb6c1b376e4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem: 7+6= | Output: 41\n",
            "Problem: 8+7= | Output: 41\n",
            "Problem: 9+2= | Output: 11\n",
            "Problem: 4+8= | Output: 21\n",
            "Problem: 3+0= | Output: 40\n",
            "Problem: 1+9= | Output: 00\n",
            "Problem: 1+3= | Output: 40\n",
            "Problem: 2+5= | Output: 70\n",
            "Problem: 2+1= | Output: 30\n",
            "Problem: 8+9= | Output: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It kinda works?"
      ],
      "metadata": {
        "id": "ugYfW72FUhWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### EX3"
      ],
      "metadata": {
        "id": "6rdCXt4hwTVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### EX4"
      ],
      "metadata": {
        "id": "0GsyP7iOs8m9"
      }
    }
  ]
}